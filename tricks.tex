\section{Tips and Tricks}

Practitioners use several tricks to improve the performance of GANs.
It can be difficult to tell how effective some of these tricks are;
many of them seem to help in some contexts and hurt in others.
These should be regarded as techniques that are worth trying out,
not as ironclad best practices.

NIPS 2016 also featured a workshop on adversarial training, with
an invited talk by Soumith Chintala called "How to train a GAN."
This talk has more or less the same goal as this portion of the tutorial,
with a different collection of advice.
To learn about tips and tricks not included in this tutorial, check
out the GitHub repository associated with Soumith's talk:

\url{https://github.com/soumith/ganhacks}


\subsection{Train with labels}

Using labels in any way, shape or form almost always results in a dramatic
improvement in the subjective quality of the samples generated by the model.
This was first observed by \citet{denton2015deep}, who built class-conditional
GANs that generated much better samples than GANs that were free to generate
from any class.
Later, \citet{Salimans-et-al-arxiv2014} found that sample quality improved
even if the generator did not explicitly incorporate class information; training
 the discriminator to recognize specific classes of real objects is sufficient.

 It is not entirely clear why this trick works.
 It may be that the incorporation of class information gives the training
 process useful clues that help with optimization.
 It may also be that this trick gives no objective improvement in sample quality,
 but instead biases the samples toward taking on properties that the human
 visual system focuses on.
 If the latter is the case, then this trick may not result in a better model
 of the true data-generating distribution, but it still helps to create media
 for a human audience to enjoy and may help an RL agent to carry out tasks
 that rely on knowledge of the same aspects of the environment that are relevant
 to human beings.

 It is important to compare results obtained using this trick only to other
 results using the same trick; models trained with labels should be compared
 only to other models trained with labels, class-conditional models should
 be compared only to other class-conditional models.
 Comparing a model that uses labels to one that does not is unfair and an
 uninteresting benchmark, much as a convolutional model can usually be expected
 to outperform a non-convolutional model on image tasks.


