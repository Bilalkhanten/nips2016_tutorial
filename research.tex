\section{Research Frontiers}

GANs are a relatively new method, with many research directions still
remaining open.

\subsection{Non-convergence}

The largest problem facing GANs that researchers should try to resolve is the issue
of non-convergence.

Most deep models are trained using an optimization algorithm that seeks out a low
value of a cost function.
While many problems can interfere with optimization, optimization algorithms usually
make reliable downhill progress.
GANs require finding the equilibrium to a game with two players.
Even if each player successfully moves downhill on that player's update,
the same update might move the other player uphill.
Sometimes the two players eventually reach an equilibrium, but in other scenarios
they repeatedly undo each others' progress without arriving anywhere useful.
This is a general problem with games not unique to GANs, so a general solution
to this problem would have wide-reaching applications.

To gain some intuition for how gradient descent performs when applied to games
rather than optimization, the reader is encouraged to solve the exercise in
\secref{sec:xy_exercise} and review its solution in \secref{sec:xy_soln} now.

